{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348bee6c-5528-4c2d-b06e-e9f99f2e0fa6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [
     "pip",
     "installation"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scanpy\n",
      "  Downloading scanpy-1.9.5-py3-none-any.whl (2.0 MB)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Collecting scikit-learn>=0.24\n",
      "  Downloading scikit_learn-1.3.0-cp39-cp39-win_amd64.whl (9.3 MB)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\a\\miniconda3\\lib\\site-packages (from scanpy) (1.5.1)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Collecting h5py>=3\n",
      "  Downloading h5py-3.9.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Collecting matplotlib>=3.4\n",
      "  Downloading matplotlib-3.8.0-cp39-cp39-win_amd64.whl (7.6 MB)\n",
      "Collecting anndata>=0.7.4\n",
      "  Downloading anndata-0.9.2-py3-none-any.whl (104 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\a\\miniconda3\\lib\\site-packages (from scanpy) (1.23.4)\n",
      "Collecting umap-learn>=0.3.10\n",
      "  Downloading umap-learn-0.5.4.tar.gz (90 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\a\\miniconda3\\lib\\site-packages (from scanpy) (21.3)\n",
      "Collecting statsmodels>=0.10.0rc2\n",
      "  Downloading statsmodels-0.14.0-cp39-cp39-win_amd64.whl (9.4 MB)\n",
      "Collecting natsort\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Collecting patsy\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Collecting numba>=0.41.0\n",
      "  Downloading numba-0.57.1-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Collecting scipy>=1.4\n",
      "  Downloading scipy-1.11.2-cp39-cp39-win_amd64.whl (44.1 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\a\\miniconda3\\lib\\site-packages (from scanpy) (4.63.0)\n",
      "Collecting networkx>=2.3\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting session-info\n",
      "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.1-cp39-cp39-win_amd64.whl (435 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.5-cp39-cp39-win_amd64.whl (56 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.42.1-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\a\\miniconda3\\lib\\site-packages (from matplotlib>=3.4->scanpy) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\a\\miniconda3\\lib\\site-packages (from matplotlib>=3.4->scanpy) (5.10.0)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-10.0.1-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\a\\miniconda3\\lib\\site-packages (from matplotlib>=3.4->scanpy) (3.0.9)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\a\\miniconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.4->scanpy) (3.10.0)\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0\n",
      "  Downloading llvmlite-0.40.1-cp39-cp39-win_amd64.whl (27.7 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\a\\miniconda3\\lib\\site-packages (from pandas>=1.0->scanpy) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\a\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.4->scanpy) (1.16.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "Collecting stdlib_list\n",
      "  Downloading stdlib_list-0.9.0-py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\a\\miniconda3\\lib\\site-packages (from tqdm->scanpy) (0.4.4)\n",
      "Building wheels for collected packages: umap-learn, pynndescent, session-info\n",
      "  Building wheel for umap-learn (setup.py): started\n",
      "  Building wheel for umap-learn (setup.py): finished with status 'done'\n",
      "  Created wheel for umap-learn: filename=umap_learn-0.5.4-py3-none-any.whl size=86781 sha256=e387ac31596e15bf309d3fac975a4972b41da8ddd53fe91f25d3049d30930f0c\n",
      "  Stored in directory: c:\\users\\a\\appdata\\local\\pip\\cache\\wheels\\e1\\8b\\ec\\51afd5b0c041b6a7dd5777ceb58cc0d645ba9454cc5a923e96\n",
      "  Building wheel for pynndescent (setup.py): started\n",
      "  Building wheel for pynndescent (setup.py): finished with status 'done'\n",
      "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55638 sha256=c167ddce62bf4ce37d01ab44dadf0014f2cde197b3adb321d1934ac24afc891f\n",
      "  Stored in directory: c:\\users\\a\\appdata\\local\\pip\\cache\\wheels\\12\\f9\\4d\\ec5ad1c823c710fcc4473669fdcffc8891f4bc398c841af22e\n",
      "  Building wheel for session-info (setup.py): started\n",
      "  Building wheel for session-info (setup.py): finished with status 'done'\n",
      "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8053 sha256=e193e40fa537dd927db46aa2798adbf46166d90e99d486455a3a88423aba5d7f\n",
      "  Stored in directory: c:\\users\\a\\appdata\\local\\pip\\cache\\wheels\\d4\\fc\\2e\\00ca60bac7954b84907efd41baa9b4853500eaeec4228410c6\n",
      "Successfully built umap-learn pynndescent session-info\n",
      "Installing collected packages: threadpoolctl, scipy, llvmlite, joblib, scikit-learn, pillow, numba, kiwisolver, fonttools, cycler, contourpy, stdlib-list, pynndescent, patsy, natsort, matplotlib, h5py, umap-learn, statsmodels, session-info, seaborn, networkx, anndata, scanpy\n",
      "Successfully installed anndata-0.9.2 contourpy-1.1.1 cycler-0.11.0 fonttools-4.42.1 h5py-3.9.0 joblib-1.3.2 kiwisolver-1.4.5 llvmlite-0.40.1 matplotlib-3.8.0 natsort-8.4.0 networkx-3.1 numba-0.57.1 patsy-0.5.3 pillow-10.0.1 pynndescent-0.5.10 scanpy-1.9.5 scikit-learn-1.3.0 scipy-1.11.2 seaborn-0.12.2 session-info-1.0.0 statsmodels-0.14.0 stdlib-list-0.9.0 threadpoolctl-3.2.0 umap-learn-0.5.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d08c3c2-822d-4de4-8eb4-601e0a08d654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b523140c-02c0-4d01-9ac8-ac2d0a834533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr1_0</th>\n",
       "      <th>chr1_1</th>\n",
       "      <th>chr1_2</th>\n",
       "      <th>chr1_3</th>\n",
       "      <th>chr1_4</th>\n",
       "      <th>chr1_5</th>\n",
       "      <th>chr1_6</th>\n",
       "      <th>chr1_7</th>\n",
       "      <th>chr1_8</th>\n",
       "      <th>chr1_9</th>\n",
       "      <th>...</th>\n",
       "      <th>chr1_190</th>\n",
       "      <th>chr1_191</th>\n",
       "      <th>chr1_192</th>\n",
       "      <th>chr1_193</th>\n",
       "      <th>chr1_194</th>\n",
       "      <th>chr1_195</th>\n",
       "      <th>chr1_196</th>\n",
       "      <th>chr1_197</th>\n",
       "      <th>chr1_198</th>\n",
       "      <th>chr1_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cell_0</th>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>77</td>\n",
       "      <td>31</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>24</td>\n",
       "      <td>65</td>\n",
       "      <td>43</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>57</td>\n",
       "      <td>96</td>\n",
       "      <td>87</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell_1</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "      <td>55</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>60</td>\n",
       "      <td>31</td>\n",
       "      <td>81</td>\n",
       "      <td>27</td>\n",
       "      <td>98</td>\n",
       "      <td>65</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell_2</th>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>95</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>97</td>\n",
       "      <td>82</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>82</td>\n",
       "      <td>63</td>\n",
       "      <td>83</td>\n",
       "      <td>29</td>\n",
       "      <td>62</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell_3</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>86</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>80</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>82</td>\n",
       "      <td>58</td>\n",
       "      <td>68</td>\n",
       "      <td>21</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cell_4</th>\n",
       "      <td>51</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        chr1_0  chr1_1  chr1_2  chr1_3  chr1_4  chr1_5  chr1_6  chr1_7  \\\n",
       "Cell_0      56       8      77      31      93      70      24      65   \n",
       "Cell_1       9      89      65      92      70      45      38      55   \n",
       "Cell_2      44      13      26      95       7      27      97      82   \n",
       "Cell_3      23       4      33      86      72      61      37       1   \n",
       "Cell_4      51      92      92      90      10      30      35      83   \n",
       "\n",
       "        chr1_8  chr1_9  ...  chr1_190  chr1_191  chr1_192  chr1_193  chr1_194  \\\n",
       "Cell_0      43      86  ...        46        78        72        32        16   \n",
       "Cell_1      66       0  ...        39         4        18        60        31   \n",
       "Cell_2      21      41  ...        24         4        87        56        82   \n",
       "Cell_3      42      64  ...        62        80        38        31        37   \n",
       "Cell_4       3      67  ...        72        25        72        80        37   \n",
       "\n",
       "        chr1_195  chr1_196  chr1_197  chr1_198  chr1_199  \n",
       "Cell_0        57        96        87        44         1  \n",
       "Cell_1        81        27        98        65        15  \n",
       "Cell_2        63        83        29        62        93  \n",
       "Cell_3        82        58        68        21        79  \n",
       "Cell_4        23        89        89        22        29  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create fake single-cell atac-seq data\n",
    "counts = pd.DataFrame(np.random.randint(0,100,size=(50, 200)),\n",
    "                    index=['Cell_'+i for i in map(str, range(50))],\n",
    "                    columns=['chr1_'+i for i in map(str, range(200))])\n",
    "\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c100c62-fee3-41a9-8deb-251016f91200",
   "metadata": {},
   "outputs": [],
   "source": [
    "atac = ad.AnnData(counts)\n",
    "sep = ('_', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66578649-4cc0-478b-8dbd-6bbb6845163c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "65541cdf-ace1-4eb3-bed0-7df04062b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame(np.random.randint(0,100,size=(50, 200)),\n",
    "                    index=['Cell_'+i for i in map(str, range(50))],\n",
    "                    columns=['chr1_'+i+'_'+i for i in map(str, range(200))])\n",
    "counts2 = pd.DataFrame(np.random.randint(0,100,size=(50, 200)),\n",
    "                    index=['Cell_'+i for i in map(str, range(50))],\n",
    "                    columns=['chr2_'+i+'_'+i for i in map(str, range(200))])\n",
    "counts = pd.concat([counts, counts2], axis=1)\n",
    "atac = ad.AnnData(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66c84406-236f-470a-acaf-58347cd03d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_region_infos(AnnData,\n",
    "                     sep = ('_', '_'),\n",
    "                     inplace=True):\n",
    "    \"\"\"\n",
    "    Get region informations from the var_names of AnnData object.\n",
    "    e.g. chr1_12345_12346 -> 'chromosome' : chr1, 'start' : 12345, 'end' : 12346\n",
    "    These info will be added to var of AnnData object.\n",
    "        adata.var['chromosome'] : chromosome\n",
    "        adata.var['start'] : start position\n",
    "        adata.var['end'] : end position\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    AnnData : AnnData object\n",
    "        AnnData object with var_names as region names.\n",
    "    sep : tuple, optional\n",
    "        Separator of region names. The default is ('_', '_').\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    AnnData : AnnData object\n",
    "        AnnData object with region informations in var.\n",
    "    \"\"\"\n",
    "    # Check if user wants to modify AnnData inplace or return a copy\n",
    "    if inplace:\n",
    "        pass\n",
    "    else:\n",
    "        AnnData = AnnData.copy()\n",
    "    regions_list = AnnData.var_names\n",
    "\n",
    "    # Replace sep[1] with sep[0] to make it easier to split\n",
    "    regions_list = regions_list.str.replace(sep[1], sep[0])\n",
    "\n",
    "    # Split region names\n",
    "    regions_list = regions_list.str.split(sep[0]).tolist()\n",
    "\n",
    "    # Check if all regions have the same number of elements\n",
    "    if set([len(i) for i in regions_list]) != set([3]):\n",
    "        raise ValueError(\"\"\"Not all regions have the same number of elements.\n",
    "                         Check if sep is correct, it should be ({}, {}),\n",
    "                         with only one occurence each in region names.\"\"\".format(sep[0], sep[1]))\n",
    "\n",
    "    # Extract region informations from var_names\n",
    "    region_infos = pd.DataFrame(regions_list,\n",
    "                                index=AnnData.var_names,\n",
    "                                columns=['chromosome', 'start', 'end'])\n",
    "    \n",
    "    # Convert start and end to int\n",
    "    region_infos['start'] = region_infos['start'].astype(int)\n",
    "    region_infos['end'] = region_infos['end'].astype(int)\n",
    "\n",
    "    # Add region informations to var\n",
    "    AnnData.var['chromosome'] = region_infos['chromosome']\n",
    "    AnnData.var['start'] = region_infos['start']\n",
    "    AnnData.var['end'] = region_infos['end']\n",
    "    \n",
    "    # Return AnnData if inplace is False\n",
    "    if inplace:\n",
    "        pass\n",
    "    else:\n",
    "        return AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "184a8995-f345-4458-b679-9a21a3525288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('_', '-')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d0062967-caee-4417-95a2-c28afa755660",
   "metadata": {},
   "outputs": [],
   "source": [
    "atac=add_region_infos(atac, sep=sep, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df8700a1-c944-4c89-a358-55d2f736c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosomes = atac.var['chromosome'].unique()\n",
    "adata_chr = [atac[:, atac.var['chromosome']==chromosome] for chromosome in chromosomes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7d5c03a0-dff7-45d3-8351-b0580d854484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[View of AnnData object with n_obs × n_vars = 50 × 200\n",
       "     var: 'chromosome', 'start', 'end',\n",
       " View of AnnData object with n_obs × n_vars = 50 × 200\n",
       "     var: 'chromosome', 'start', 'end']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_chr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b560e1d0-4171-4e38-b32e-51391d8cb8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 50 × 200\n",
       "    var: 'chromosome', 'start', 'end'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = adata_chr[0]\n",
    "adata    [:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce9d58-5943-41b0-9935-0096b729c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#' Create cicero input CDS\n",
    "#'\n",
    "#' Function to generate an aggregated input CDS for cicero. \\code{run_cicero}\n",
    "#' takes as input an aggregated cicero CDS object. This function will generate\n",
    "#' the CDS given an input CDS (perhaps generated by  \\code{make_atac_cds}) and\n",
    "#' a value for k, which is the number of cells to be aggregated per bin. The\n",
    "#' default value for k is 50.\n",
    "#'\n",
    "#' @param cds Input CDS object.\n",
    "#' @param reduced_coordinates A data frame with columns representing the\n",
    "#'   coordinates of each cell in reduced dimension space (generally 2-3\n",
    "#'   dimensions). \\code{row.names(reduced_coordinates)} should match the cell\n",
    "#'   names in the CDS object. If dimension reduction was done using monocle,\n",
    "#'   tSNE coordinates can be accessed by \\code{t(reducedDimA(cds))}, and\n",
    "#'   DDRTree coordinates can be accessed by \\code{t(reducedDimS(cds))}.\n",
    "#' @param k Number of cells to aggregate per bin.\n",
    "#' @param summary_stats Which numeric \\code{pData(cds)} columns you would like\n",
    "#'   summarized (mean) by bin in the resulting CDS object.\n",
    "#' @param size_factor_normalize Logical, should accessibility values be\n",
    "#'   normalized by size factor?\n",
    "#' @param silent Logical, should warning and info messages be printed?\n",
    "#' @param return_agg_info Logical, should a list of the assignments of cells to\n",
    "#'   aggregated bins be output? When \\code{TRUE}, this function returns a list \n",
    "#'   of two items, first, the aggregated CDS object and second, a data.frame \n",
    "#'   with the binning information.\n",
    "#'\n",
    "#' @details Aggregation of similar cells is done using a k-nearest-neighbors\n",
    "#'   graph and a randomized \"bagging\" procedure. Details are available in the\n",
    "#'   publication that accompanies this package. Run \\code{citation(\"cicero\")}\n",
    "#'   for publication details. KNN is calculated using\n",
    "#'   \\code{\\link[FNN]{knn.index}}\n",
    "#'\n",
    "#' @return Aggregated CDS object. If return_agg_info is \\code{TRUE}, a list \n",
    "#'   of the aggregated CDS object and a data.frame of aggregation info.\n",
    "#' @export\n",
    "#'\n",
    "#' @examples\n",
    "#' \\dontrun{\n",
    "#'   data(\"cicero_data\")\n",
    "#'\n",
    "#'   input_cds <- make_atac_cds(cicero_data, binarize = TRUE)\n",
    "#'   input_cds <- reduceDimension(input_cds, max_components = 2, num_dim=6,\n",
    "#'                                reduction_method = 'tSNE',\n",
    "#'                                norm_method = \"none\")\n",
    "#'   tsne_coords <- t(reducedDimA(input_cds))\n",
    "#'   row.names(tsne_coords) <- row.names(pData(input_cds))\n",
    "#'   cicero_cds <- make_cicero_cds(input_cds, reduced_coordinates = tsne_coords)\n",
    "#' }\n",
    "#'\n",
    "make_cicero_cds <- function(cds,\n",
    "                            reduced_coordinates,\n",
    "                            k=50,\n",
    "                            summary_stats = NULL,\n",
    "                            size_factor_normalize = TRUE,\n",
    "                            silent = FALSE, \n",
    "                            return_agg_info = FALSE) {\n",
    "  \n",
    "  assertthat::assert_that(is(cds, \"CellDataSet\"))\n",
    "  assertthat::assert_that(is.data.frame(reduced_coordinates) |\n",
    "                            is.matrix(reduced_coordinates))\n",
    "  assertthat::assert_that(assertthat::are_equal(nrow(reduced_coordinates),\n",
    "                                                nrow(pData(cds))))\n",
    "  assertthat::assert_that(setequal(row.names(reduced_coordinates),\n",
    "                                   colnames(cds)))\n",
    "  assertthat::assert_that(assertthat::is.count(k) & k > 1)\n",
    "  assertthat::assert_that(is.character(summary_stats) | is.null(summary_stats))\n",
    "  if(!is.null(summary_stats)) {\n",
    "    assertthat::assert_that(all(summary_stats %in% names(pData(cds))),\n",
    "                            msg = paste(\"One of your summary_stats is missing\",\n",
    "                                        \"from your pData table. Either add a\",\n",
    "                                        \"column with the name in\",\n",
    "                                        \"summary_stats, or remove the name\",\n",
    "                                        \"from the summary_stats parameter.\",\n",
    "                                        collapse = \" \"))\n",
    "    assertthat::assert_that(sum(vapply(summary_stats, function(x) {\n",
    "      !(is(pData(cds)[,x], \"numeric\") | is(pData(cds)[,x], \"integer\"))}, 1)) == 0,\n",
    "                            msg = paste(\"All columns in summary_stats must be\",\n",
    "                                        \"of class numeric or integer.\",\n",
    "                                        collapse = \" \"))\n",
    "  }\n",
    "  assertthat::assert_that(is.logical(size_factor_normalize))\n",
    "  assertthat::assert_that(is.logical(silent))\n",
    "  assertthat::assert_that(is.logical(return_agg_info))\n",
    "  \n",
    "  reduced_coordinates <- as.data.frame(reduced_coordinates)\n",
    "  \n",
    "  reduced_coordinates <- reduced_coordinates[colnames(cds),]\n",
    "  \n",
    "  # Create a k-nearest neighbors map\n",
    "  nn_map <- FNN::knn.index(reduced_coordinates, k=(k-1)) # no data.frame wrapper\n",
    "  \n",
    "  row.names(nn_map) <- row.names(reduced_coordinates)\n",
    "  \n",
    "  nn_map <- cbind(nn_map, seq_len(nrow(nn_map)))\n",
    "  \n",
    "  good_choices <- seq_len(nrow(nn_map))\n",
    "  choice <- sample(seq_len(length(good_choices)), size = 1, replace = FALSE)\n",
    "  chosen <- good_choices[choice]\n",
    "  good_choices <- good_choices[good_choices != good_choices[choice]]\n",
    "  it <- 0\n",
    "  k2 <- k * 2 # Compute once\n",
    "  \n",
    "  # function for sapply\n",
    "  get_shared <- function(other, this_choice) {\n",
    "    k2 - length(union(cell_sample[other,], this_choice))\n",
    "  }\n",
    "  \n",
    "  while (length(good_choices) > 0 & it < 5000) { # slow\n",
    "    it <- it + 1\n",
    "    choice <- sample(seq_len(length(good_choices)), size = 1, replace = FALSE)\n",
    "    new_chosen <- c(chosen, good_choices[choice])\n",
    "    good_choices <- good_choices[good_choices != good_choices[choice]]\n",
    "    cell_sample <- nn_map[new_chosen,]\n",
    "\n",
    "    others <- seq_len(nrow(cell_sample) - 1)\n",
    "    this_choice <- cell_sample[nrow(cell_sample),]\n",
    "    shared <- sapply(others, get_shared, this_choice = this_choice)\n",
    "    \n",
    "    if (max(shared) < .9 * k) {\n",
    "      chosen <- new_chosen\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  cell_sample <- nn_map[chosen,]\n",
    "  \n",
    "  if(!silent) {\n",
    "    # Only need this slow step if !silent\n",
    "    combs <- combn(nrow(cell_sample), 2)\n",
    "    \n",
    "    shared <- apply(combs, 2, function(x) {  #slow\n",
    "      k2 - length(unique(as.vector(cell_sample[x,])))\n",
    "    })\n",
    "    \n",
    "    message(paste0(\"Overlap QC metrics:\\nCells per bin: \", k,\n",
    "                   \"\\nMaximum shared cells bin-bin: \", max(shared),\n",
    "                   \"\\nMean shared cells bin-bin: \", mean(shared),\n",
    "                   \"\\nMedian shared cells bin-bin: \", median(shared)))\n",
    "    \n",
    "    if (mean(shared)/k > .1)\n",
    "      warning(\"On average, more than 10% of cells are shared between paired bins.\")\n",
    "  }\n",
    "  \n",
    "  exprs_old <- exprs(cds)\n",
    "  \n",
    "  mask <- sapply(seq_len(nrow(cell_sample)), \n",
    "                 function(x) seq_len(ncol(exprs_old)) %in% cell_sample[x,,drop=FALSE])\n",
    "  \n",
    "  if (return_agg_info) {\n",
    "    row.names(mask) <- colnames(exprs_old)\n",
    "    colnames(mask) <- paste0(\"agg_\", chosen)\n",
    "    agg_map <- reshape2::melt(mask)\n",
    "    agg_map <- agg_map[agg_map$value,]\n",
    "    agg_map$value <- NULL\n",
    "    names(agg_map) <- c(\"cell\", \"agg_cell\")\n",
    "  }\n",
    "  \n",
    "  mask <- Matrix::Matrix(mask)\n",
    "  new_exprs <- exprs_old %*% mask\n",
    "  \n",
    "  new_exprs <- Matrix::t(new_exprs)\n",
    "  new_exprs <- as.matrix(new_exprs)\n",
    "  \n",
    "  pdata <- pData(cds)\n",
    "  new_pcols <- \"agg_cell\"\n",
    "  if(!is.null(summary_stats)) { \n",
    "    new_pcols <- c(new_pcols, paste0(\"mean_\",summary_stats)) \n",
    "  }\n",
    "  \n",
    "  new_pdata <- plyr::adply(cell_sample,1, function(x) {\n",
    "    sub <- pdata[x,]\n",
    "    df_l <- list()\n",
    "    df_l[\"temp\"] <- 1\n",
    "    for (att in summary_stats) {\n",
    "      df_l[paste0(\"mean_\", att)] <- mean(sub[,att])\n",
    "    }\n",
    "    data.frame(df_l)\n",
    "  })\n",
    "  \n",
    "  new_pdata$agg_cell <- paste(\"agg\", chosen, sep=\"\")\n",
    "  new_pdata <- new_pdata[,new_pcols, drop = FALSE] # fixes order, drops X1 and temp\n",
    "  \n",
    "  row.names(new_pdata) <- new_pdata$agg_cell\n",
    "  row.names(new_exprs) <- new_pdata$agg_cell\n",
    "  new_exprs <- as.matrix(t(new_exprs))\n",
    "  \n",
    "  fdf <- fData(cds)\n",
    "  new_pdata$temp <- NULL\n",
    "  \n",
    "  fd <- new(\"AnnotatedDataFrame\", data = fdf)\n",
    "  pd <- new(\"AnnotatedDataFrame\", data = new_pdata)\n",
    "  \n",
    "  cicero_cds <-  suppressWarnings(newCellDataSet(new_exprs,\n",
    "                                                 phenoData = pd,\n",
    "                                                 featureData = fd,\n",
    "                                                 expressionFamily=negbinomial.size(),\n",
    "                                                 lowerDetectionLimit=0))\n",
    "  \n",
    "  cicero_cds <- monocle::detectGenes(cicero_cds, min_expr = .1)\n",
    "  cicero_cds <- estimateSizeFactorsSimp(cicero_cds)\n",
    "  #cicero_cds <- suppressWarnings(BiocGenerics::estimateDispersions(cicero_cds))\n",
    "\n",
    "  if (any(!c(\"chr\", \"bp1\", \"bp2\") %in% names(fData(cicero_cds)))) {\n",
    "    fData(cicero_cds)$chr <- NULL\n",
    "    fData(cicero_cds)$bp1 <- NULL\n",
    "    fData(cicero_cds)$bp2 <- NULL\n",
    "    fData(cicero_cds) <- cbind(fData(cicero_cds),\n",
    "                               df_for_coords(row.names(fData(cicero_cds))))\n",
    "  }\n",
    "  \n",
    "  if (size_factor_normalize) {\n",
    "    Biobase::exprs(cicero_cds) <-\n",
    "      t(t(Biobase::exprs(cicero_cds))/Biobase::pData(cicero_cds)$Size_Factor)\n",
    "  }\n",
    "  \n",
    "  if (return_agg_info) {\n",
    "    return(list(cicero_cds, agg_map))\n",
    "  }\n",
    "  cicero_cds\n",
    "}\n",
    "\n",
    "\n",
    "#' Run Cicero\n",
    "#'\n",
    "#' A wrapper function that runs the primary functions of the Cicero pipeline\n",
    "#' with default parameters. Runs \\code{\\link{estimate_distance_parameter}},\n",
    "#' \\code{\\link{generate_cicero_models}} and \\code{\\link{assemble_connections}}.\n",
    "#' See the manual pages of these functions for details about their function and\n",
    "#' parameter options. Defaults in this function are designed for mammalian data,\n",
    "#' those with non-mammalian data should read about parameters in the above\n",
    "#' functions.\n",
    "#'\n",
    "#' @param cds Cicero CDS object, created using \\code{\\link{make_cicero_cds}}\n",
    "#' @param window Size of the genomic window to query, in base pairs.\n",
    "#' @param silent Whether to print progress messages\n",
    "#' @param sample_num How many sample genomic windows to use to generate\n",
    "#'   \\code{distance_parameter} parameter. Default: 100.\n",
    "#' @param genomic_coords Either a data frame or a path (character) to a file\n",
    "#'   with chromosome lengths. The file should have two columns, the first is\n",
    "#'   the chromosome name (ex. \"chr1\") and the second is the chromosome length\n",
    "#'   in base pairs. See \\code{data(human.hg19.genome)} for an example. If a\n",
    "#'   file, should be tab-separated and without header.\n",
    "#'\n",
    "#' @return A table of co-accessibility scores\n",
    "#' @export\n",
    "#'\n",
    "#' @examples\n",
    "#'   data(\"cicero_data\")\n",
    "#'   data(\"human.hg19.genome\")\n",
    "#'   sample_genome <- subset(human.hg19.genome, V1 == \"chr18\")\n",
    "#'   sample_genome$V2[1] <- 100000\n",
    "#'   input_cds <- make_atac_cds(cicero_data, binarize = TRUE)\n",
    "#'   input_cds <- reduceDimension(input_cds, max_components = 2, num_dim=6,\n",
    "#'                                reduction_method = 'tSNE',\n",
    "#'                                norm_method = \"none\")\n",
    "#'   tsne_coords <- t(reducedDimA(input_cds))\n",
    "#'   row.names(tsne_coords) <- row.names(pData(input_cds))\n",
    "#'   cicero_cds <- make_cicero_cds(input_cds, reduced_coordinates = tsne_coords)\n",
    "#'   cons <- run_cicero(cicero_cds, sample_genome, sample_num = 2)\n",
    "#'\n",
    "run_cicero <- function(cds,\n",
    "                       genomic_coords,\n",
    "                       window = 500000,\n",
    "                       silent=FALSE,\n",
    "                       sample_num = 100) {\n",
    "  # Check input\n",
    "  assertthat::assert_that(is(cds, \"CellDataSet\"))\n",
    "  assertthat::assert_that(is.logical(silent))\n",
    "  assertthat::assert_that(assertthat::is.number(window))\n",
    "  assertthat::assert_that(assertthat::is.count(sample_num))\n",
    "  if (!is.data.frame(genomic_coords)) {\n",
    "    assertthat::is.readable(genomic_coords)\n",
    "  }\n",
    "\n",
    "  if (!silent) print(\"Starting Cicero\")\n",
    "  if (!silent) print(\"Calculating distance_parameter value\")\n",
    "  distance_parameters <- estimate_distance_parameter(cds, window=window,\n",
    "                                  maxit=100, sample_num = sample_num,\n",
    "                                   distance_constraint = 250000,\n",
    "                                   distance_parameter_convergence = 1e-22,\n",
    "                                   genomic_coords = genomic_coords)\n",
    "\n",
    "  mean_distance_parameter <- mean(unlist(distance_parameters))\n",
    "\n",
    "  if (!silent) print(\"Running models\")\n",
    "  cicero_out <-\n",
    "    generate_cicero_models(cds,\n",
    "                           distance_parameter = mean_distance_parameter,\n",
    "                           window = window,\n",
    "                           genomic_coords = genomic_coords)\n",
    "\n",
    "  if (!silent) print(\"Assembling connections\")\n",
    "  all_cons <- assemble_connections(cicero_out, silent=silent)\n",
    "\n",
    "  if (!silent) print(\"Done\")\n",
    "  all_cons\n",
    "  }\n",
    "\n",
    "\n",
    "#' Calculate distance penalty parameter\n",
    "#'\n",
    "#' Function to calculate distance penalty parameter (\\code{distance_parameter})\n",
    "#' for random genomic windows. Used to choose \\code{distance_parameter} to pass\n",
    "#' to \\code{\\link{generate_cicero_models}}.\n",
    "#'\n",
    "#' @param cds A cicero CDS object generated using \\code{\\link{make_cicero_cds}}.\n",
    "#' @param window Size of the genomic window to query, in base pairs.\n",
    "#' @param maxit Maximum number of iterations for distance_parameter estimation.\n",
    "#' @param s Power law value. See details for more information.\n",
    "#' @param sample_num Number of random windows to calculate\n",
    "#'   \\code{distance_parameter} for.\n",
    "#' @param distance_constraint Maximum distance of expected connections. Must be\n",
    "#'   smaller than \\code{window}.\n",
    "#' @param distance_parameter_convergence Convergence step size for\n",
    "#'   \\code{distance_parameter} calculation.\n",
    "#' @param max_elements Maximum number of elements per window allowed. Prevents\n",
    "#'   very large models from slowing performance.\n",
    "#' @param genomic_coords Either a data frame or a path (character) to a file\n",
    "#'   with chromosome lengths. The file should have two columns, the first is\n",
    "#'   the chromosome name (ex. \"chr1\") and the second is the chromosome length\n",
    "#'   in base pairs. See \\code{data(human.hg19.genome)} for an example. If a\n",
    "#'   file, should be tab-separated and without header.\n",
    "#' @param max_sample_windows Maximum number of random windows to screen to find\n",
    "#'   sample_num windows for distance calculation. Default 500.\n",
    "#'\n",
    "#' @examples\n",
    "#'   data(\"cicero_data\")\n",
    "#'   data(\"human.hg19.genome\")\n",
    "#'   sample_genome <- subset(human.hg19.genome, V1 == \"chr18\")\n",
    "#'   sample_genome$V2[1] <- 100000\n",
    "#'   input_cds <- make_atac_cds(cicero_data, binarize = TRUE)\n",
    "#'   input_cds <- reduceDimension(input_cds, max_components = 2, num_dim=6,\n",
    "#'                                reduction_method = 'tSNE',\n",
    "#'                                norm_method = \"none\")\n",
    "#'   tsne_coords <- t(reducedDimA(input_cds))\n",
    "#'   row.names(tsne_coords) <- row.names(pData(input_cds))\n",
    "#'   cicero_cds <- make_cicero_cds(input_cds, reduced_coordinates = tsne_coords)\n",
    "#'   distance_parameters <- estimate_distance_parameter(cicero_cds,\n",
    "#'                                                      sample_num=5,\n",
    "#'                                                      genomic_coords = sample_genome)\n",
    "#'\n",
    "#' @seealso \\code{\\link{generate_cicero_models}}\n",
    "#' @return A list of results of length \\code{sample_num}. List members are\n",
    "#'   numeric \\code{distance_parameter} values.\n",
    "#'\n",
    "#' @details The purpose of this function is to calculate the distance scaling\n",
    "#'   parameter used to adjust the distance-based penalty function used in\n",
    "#'   Cicero's model calculation. The scaling parameter, in combination with the\n",
    "#'   power law value \\code{s} determines the distance-based penalty.\n",
    "#'\n",
    "#'   This function chooses random windows of the genome and calculates a\n",
    "#'   \\code{distance_parameter}. The function returns a vector of values\n",
    "#'   calculated on these random windows. We recommend using the mean value of\n",
    "#'   this vector moving forward with Cicero analysis.\n",
    "#'\n",
    "#'   The function works by finding the minimum distance scaling parameter such\n",
    "#'   that no more than 5% of pairs of sites at a distance greater than\n",
    "#'   \\code{distance_constraint} have non-zero entries after graphical lasso\n",
    "#'   regularization and such that fewer than 80% of all output entries are\n",
    "#'   nonzero.\n",
    "#'\n",
    "#'   If the chosen random window has fewer than 2 or greater than\n",
    "#'   \\code{max_elements} sites, the window is skipped. In addition, the random\n",
    "#'   window will be skipped if there are insufficient long-range comparisons\n",
    "#'   (see below) to be made. The \\code{max_elements} parameter exist to prevent\n",
    "#'   very dense windows from slowing the calculation. If you expect that your\n",
    "#'   data may regularly have this many sites in a window, you will need to\n",
    "#'   raise this parameter.\n",
    "#'\n",
    "#'   Calculating the \\code{distance_parameter} in a sample window requires\n",
    "#'   peaks in that window that are at a distance greater than the\n",
    "#'   \\code{distance_constraint} parameter. If there are not enough examples at\n",
    "#'   high distance have been found, the function will return the warning \n",
    "#'   \\code{\"Warning: could not calculate sample_num distance_parameters - see \n",
    "#'   documentation details\"}.When looking for \\code{sample_num} example \n",
    "#'   windows, the function will search \\code{max_sample_windows} windows. By \n",
    "#'   default this is set at 500, which should be well beyond the 100 windows \n",
    "#'   that need to be found. However, in very sparse datasets, increasing \n",
    "#'   \\code{max_sample_windows} may help avoid the above warning. Increasing \n",
    "#'   \\code{max_sample_windows} may slow performance in sparse datasets. If you \n",
    "#'   are still not able to get enough example windows, even with a large\n",
    "#'   \\code{max_sample_windows} paramter, this may mean your \\code{window} \n",
    "#'   parameter needs to be larger or your \\code{distance_constraint} parameter \n",
    "#'   needs to be smaller. A less likely possibility is that your \n",
    "#'   \\code{max_elements} parameter needs to be larger. This would occur if your \n",
    "#'   data is particularly dense.\n",
    "#'\n",
    "#'   The parameter \\code{s} is a constant that captures the power-law\n",
    "#'   distribution of contact frequencies between different locations in the\n",
    "#'   genome as a function of their linear distance. For a complete discussion\n",
    "#'   of the various polymer models of DNA packed into the nucleus and of\n",
    "#'   justifiable values for s, we refer readers to (Dekker et al., 2013) for a\n",
    "#'   discussion of justifiable values for s. We use a value of 0.75 by default\n",
    "#'   in Cicero, which corresponds to the “tension globule” polymer model of DNA\n",
    "#'   (Sanborn et al., 2015). This parameter must be the same as the s parameter\n",
    "#'   for generate_cicero_models.\n",
    "#'\n",
    "#'   Further details are available in the publication that accompanies this\n",
    "#'   package. Run \\code{citation(\"cicero\")} for publication details.\n",
    "#'\n",
    "#' @references\n",
    "#'   \\itemize{\n",
    "#'     \\item Dekker, J., Marti-Renom, M.A., and Mirny, L.A. (2013). Exploring\n",
    "#'     the three-dimensional organization of genomes: interpreting chromatin\n",
    "#'     interaction data. Nat. Rev. Genet. 14, 390–403.\n",
    "#'     \\item Sanborn, A.L., Rao, S.S.P., Huang, S.-C., Durand, N.C., Huntley,\n",
    "#'     M.H., Jewett, A.I., Bochkov, I.D., Chinnappan, D., Cutkosky, A., Li, J.,\n",
    "#'     et al. (2015). Chromatin extrusion explains key features of loop and\n",
    "#'     domain formation in wild-type and engineered genomes. Proc. Natl. Acad.\n",
    "#'     Sci. U. S. A. 112, E6456–E6465.\n",
    "#'   }\n",
    "#' @export\n",
    "estimate_distance_parameter <- function(cds,\n",
    "                                   window=500000,\n",
    "                                   maxit=100,\n",
    "                                   s=0.75,\n",
    "                                   sample_num = 100,\n",
    "                                   distance_constraint = 250000,\n",
    "                                   distance_parameter_convergence = 1e-22,\n",
    "                                   max_elements = 200,\n",
    "                                   genomic_coords = cicero::human.hg19.genome,\n",
    "                                   max_sample_windows = 500) {\n",
    "\n",
    "  assertthat::assert_that(is(cds, \"CellDataSet\"))\n",
    "  assertthat::assert_that(assertthat::is.number(window))\n",
    "  assertthat::assert_that(assertthat::is.count(maxit))\n",
    "  assertthat::assert_that(assertthat::is.number(s), s < 1, s > 0)\n",
    "  assertthat::assert_that(assertthat::is.count(sample_num))\n",
    "  assertthat::assert_that(assertthat::is.count(distance_constraint))\n",
    "  assertthat::assert_that(distance_constraint < window)\n",
    "  assertthat::assert_that(assertthat::is.number(distance_parameter_convergence))\n",
    "  if (!is.data.frame(genomic_coords)) {\n",
    "    assertthat::is.readable(genomic_coords)\n",
    "  }\n",
    "  assertthat::assert_that(assertthat::is.count(max_sample_windows))\n",
    "\n",
    "  grs <- generate_windows(window, genomic_coords)\n",
    "\n",
    "  fData(cds)$chr <- gsub(\"chr\", \"\", fData(cds)$chr)\n",
    "  fData(cds)$bp1 <- as.numeric(as.character(fData(cds)$bp1))\n",
    "  fData(cds)$bp2 <- as.numeric(as.character(fData(cds)$bp2))\n",
    "\n",
    "  distance_parameters <- list()\n",
    "  distance_parameters_calced <- 0\n",
    "  it <- 0\n",
    "\n",
    "  while(sample_num > distance_parameters_calced & it < max_sample_windows) {\n",
    "    it <- it + 1\n",
    "    win <- sample(seq_len(length(grs)), 1)\n",
    "    GL <- \"Error\"\n",
    "    win_range <- get_genomic_range(grs, cds, win)\n",
    "\n",
    "    if (nrow(exprs(win_range))<=1) {\n",
    "      next()\n",
    "    }\n",
    "    if (nrow(exprs(win_range)) > max_elements) {\n",
    "      next()\n",
    "    }\n",
    "\n",
    "    dist_matrix <- calc_dist_matrix(win_range)\n",
    "\n",
    "    distance_parameter <- find_distance_parameter(dist_matrix,\n",
    "                        win_range,\n",
    "                        maxit = maxit,\n",
    "                        null_rho = 0,\n",
    "                        s,\n",
    "                        distance_constraint = distance_constraint,\n",
    "                        distance_parameter_convergence =\n",
    "                          distance_parameter_convergence)\n",
    "\n",
    "    if (!is(distance_parameter, \"numeric\")) next()\n",
    "    distance_parameters = c(distance_parameters, distance_parameter)\n",
    "    distance_parameters_calced <- distance_parameters_calced + 1\n",
    "  }\n",
    "\n",
    "  if(length(distance_parameters) < sample_num)\n",
    "    warning(paste0(\"Could not calculate sample_num distance_parameters (\",\n",
    "                   length(distance_parameters), \" were calculated) - see \",\n",
    "                   \"documentation details\"))\n",
    "  if(length(distance_parameters) == 0)\n",
    "    stop(\"No distance_parameters calculated\")\n",
    "\n",
    "  unlist(distance_parameters)\n",
    "}\n",
    "\n",
    "\n",
    "#' Generate cicero models\n",
    "#'\n",
    "#' Function to generate graphical lasso models on all sites in a CDS object\n",
    "#' within overlapping genomic windows.\n",
    "#'\n",
    "#' @param cds A cicero CDS object generated using \\code{\\link{make_cicero_cds}}.\n",
    "#' @param distance_parameter Distance based penalty parameter value. Generally,\n",
    "#'   the mean of the calculated \\code{distance_parameter} values from\n",
    "#'   \\code{\\link{estimate_distance_parameter}}.\n",
    "#' @param s Power law value. See details.\n",
    "#' @param window Size of the genomic window to query, in base pairs.\n",
    "#' @param max_elements Maximum number of elements per window allowed. Prevents\n",
    "#'   very large models from slowing performance.\n",
    "#' @param genomic_coords Either a data frame or a path (character) to a file\n",
    "#'   with chromosome lengths. The file should have two columns, the first is\n",
    "#'   the chromosome name (ex. \"chr1\") and the second is the chromosome length\n",
    "#'   in base pairs. See \\code{data(human.hg19.genome)} for an example. If a\n",
    "#'   file, should be tab-separated and without header.\n",
    "#'\n",
    "#' @details The purpose of this function is to compute the raw covariances\n",
    "#'   between each pair of sites within overlapping windows of the genome.\n",
    "#'   Within each window, the function then estimates a regularized correlation\n",
    "#'   matrix using the graphical LASSO (Friedman et al., 2008), penalizing pairs\n",
    "#'   of distant sites more than proximal sites. The scaling parameter,\n",
    "#'   \\code{distance_parameter}, in combination with the power law value \\code{s}\n",
    "#'   determines the distance-based penalty.\n",
    "#'\n",
    "#'   The parameter \\code{s} is a constant that captures the power-law\n",
    "#'   distribution of contact frequencies between different locations in the\n",
    "#'   genome as a function of their linear distance. For a complete discussion\n",
    "#'   of the various polymer models of DNA packed into the nucleus and of\n",
    "#'   justifiable values for s, we refer readers to (Dekker et al., 2013) for a\n",
    "#'   discussion of justifiable values for s. We use a value of 0.75 by default\n",
    "#'   in Cicero, which corresponds to the “tension globule” polymer model of DNA\n",
    "#'   (Sanborn et al., 2015). This parameter must be the same as the s parameter\n",
    "#'   for \\code{\\link{estimate_distance_parameter}}.\n",
    "#'\n",
    "#'   Further details are available in the publication that accompanies this\n",
    "#'   package. Run \\code{citation(\"cicero\")} for publication details.\n",
    "#'\n",
    "#' @return A list of results for each window. Either a \\code{glasso} object, or\n",
    "#'   a character description of why the window was skipped. This list can be\n",
    "#'   directly input into \\code{\\link{assemble_connections}} to create a\n",
    "#'   reconciled list of cicero co-accessibility scores.\n",
    "#' @examples\n",
    "#'   data(\"cicero_data\")\n",
    "#'   data(\"human.hg19.genome\")\n",
    "#'   sample_genome <- subset(human.hg19.genome, V1 == \"chr18\")\n",
    "#'   sample_genome$V2[1] <- 100000\n",
    "#'   input_cds <- make_atac_cds(cicero_data, binarize = TRUE)\n",
    "#'   input_cds <- reduceDimension(input_cds, max_components = 2, num_dim=6,\n",
    "#'                                reduction_method = 'tSNE',\n",
    "#'                                norm_method = \"none\")\n",
    "#'   tsne_coords <- t(reducedDimA(input_cds))\n",
    "#'   row.names(tsne_coords) <- row.names(pData(input_cds))\n",
    "#'   cicero_cds <- make_cicero_cds(input_cds, reduced_coordinates = tsne_coords)\n",
    "#'   model_output <- generate_cicero_models(cicero_cds,\n",
    "#'                                          distance_parameter = 0.3,\n",
    "#'                                          genomic_coords = sample_genome)\n",
    "#'\n",
    "#' @references\n",
    "#'   \\itemize{\n",
    "#'     \\item Dekker, J., Marti-Renom, M.A., and Mirny, L.A. (2013). Exploring\n",
    "#'     the three-dimensional organization of genomes: interpreting chromatin\n",
    "#'     interaction data. Nat. Rev. Genet. 14, 390–403.\n",
    "#'     \\item Friedman, J., Hastie, T., and Tibshirani, R. (2008). Sparse\n",
    "#'     inverse covariance estimation with the graphical lasso. Biostatistics 9,\n",
    "#'     432–441.\n",
    "#'     \\item Sanborn, A.L., Rao, S.S.P., Huang, S.-C., Durand, N.C., Huntley,\n",
    "#'     M.H., Jewett, A.I., Bochkov, I.D., Chinnappan, D., Cutkosky, A., Li, J.,\n",
    "#'     et al. (2015). Chromatin extrusion explains key features of loop and\n",
    "#'     domain formation in wild-type and engineered genomes. Proc. Natl. Acad.\n",
    "#'     Sci. U. S. A. 112, E6456–E6465.\n",
    "#'   }\n",
    "#'\n",
    "#' @seealso \\code{\\link{estimate_distance_parameter}}\n",
    "#' @export\n",
    "#'\n",
    "generate_cicero_models <- function(cds,\n",
    "                                   distance_parameter,\n",
    "                                   s = 0.75,\n",
    "                                   window = 500000,\n",
    "                                   max_elements = 200,\n",
    "                                   genomic_coords = cicero::human.hg19.genome) {\n",
    "\n",
    "  assertthat::assert_that(is(cds, \"CellDataSet\"))\n",
    "  assertthat::assert_that(assertthat::is.number(distance_parameter))\n",
    "  assertthat::assert_that(assertthat::is.number(s), s < 1, s > 0)\n",
    "  assertthat::assert_that(assertthat::is.number(window))\n",
    "  assertthat::assert_that(assertthat::is.count(max_elements))\n",
    "  if (!is.data.frame(genomic_coords)) {\n",
    "    assertthat::is.readable(genomic_coords)\n",
    "  }\n",
    "\n",
    "  grs <- generate_windows(window, genomic_coords)\n",
    "\n",
    "  fData(cds)$chr <- gsub(\"chr\", \"\", fData(cds)$chr)\n",
    "  fData(cds)$bp1 <- as.numeric(as.character(fData(cds)$bp1))\n",
    "  fData(cds)$bp2 <- as.numeric(as.character(fData(cds)$bp2))\n",
    "\n",
    "  outlist <- parallel::mclapply(seq_len(length(grs)), mc.cores = 1, function(win) {\n",
    "    GL <- \"Error\"\n",
    "\n",
    "    win_range <- get_genomic_range(grs, cds, win)\n",
    "\n",
    "    if (nrow(exprs(win_range))<=1) {\n",
    "      return(\"Zero or one element in range\")\n",
    "    }\n",
    "    if (nrow(exprs(win_range)) > max_elements) {\n",
    "      return(\"Too many elements in range\")\n",
    "    }\n",
    "\n",
    "    dist_matrix <- calc_dist_matrix(win_range)\n",
    "\n",
    "    rho_mat <- get_rho_mat(dist_matrix, distance_parameter, s)\n",
    "\n",
    "    vals <- exprs(win_range)\n",
    "    cov_mat <- cov(t(vals))\n",
    "    diag(cov_mat) <- diag(cov_mat) + 1e-4\n",
    "\n",
    "    GL <- glasso::glasso(cov_mat, rho_mat)\n",
    "    colnames(GL$w) <- row.names(GL$w) <- row.names(vals)\n",
    "    colnames(GL$wi) <- row.names(GL$wi) <- row.names(vals)\n",
    "    return(GL)\n",
    "  })\n",
    "  names_df <- as.data.frame(grs)\n",
    "  names(outlist) <- paste(names_df$seqnames,\n",
    "                          names_df$start,\n",
    "                          names_df$end, sep=\"_\")\n",
    "\n",
    "  #FIXME add warning about how many regions removed due to too many elements\n",
    "  outlist\n",
    "}\n",
    "\n",
    "#' Combine and reconcile cicero models\n",
    "#'\n",
    "#' Function which takes the output of \\code{\\link{generate_cicero_models}} and\n",
    "#' assembles the connections into a data frame with cicero co-accessibility\n",
    "#' scores.\n",
    "#'\n",
    "#' This function combines glasso models computed on overlapping windows of the\n",
    "#' genome. Pairs of sites whose regularized correlation was calculated twice\n",
    "#' are first checked for qualitative concordance (both zero, positive or\n",
    "#' negative). If they not concordant, NA is returned. If they are concordant\n",
    "#' the mean is returned.\n",
    "#'\n",
    "#' @param cicero_model_list A list of cicero output objects, generally, the\n",
    "#'   output of \\code{\\link{generate_cicero_models}}.\n",
    "#' @param silent Logical, should the function run silently?\n",
    "#'\n",
    "#' @return A data frame of connections with their cicero co-accessibility\n",
    "#'   scores.\n",
    "#' @examples\n",
    "#'   data(\"cicero_data\")\n",
    "#'   data(\"human.hg19.genome\")\n",
    "#'   sample_genome <- subset(human.hg19.genome, V1 == \"chr18\")\n",
    "#'   sample_genome$V2[1] <- 100000\n",
    "#'   input_cds <- make_atac_cds(cicero_data, binarize = TRUE)\n",
    "#'   input_cds <- reduceDimension(input_cds, max_components = 2, num_dim=6,\n",
    "#'                                reduction_method = 'tSNE',\n",
    "#'                                norm_method = \"none\")\n",
    "#'   tsne_coords <- t(reducedDimA(input_cds))\n",
    "#'   row.names(tsne_coords) <- row.names(pData(input_cds))\n",
    "#'   cicero_cds <- make_cicero_cds(input_cds, reduced_coordinates = tsne_coords)\n",
    "#'   model_output <- generate_cicero_models(cicero_cds,\n",
    "#'                                          distance_parameter = 0.3,\n",
    "#'                                          genomic_coords = sample_genome)\n",
    "#'   cicero_cons <- assemble_connections(model_output)\n",
    "#'\n",
    "#' @seealso \\code{\\link{generate_cicero_models}}\n",
    "#' @importFrom data.table melt.data.table\n",
    "#' @export\n",
    "assemble_connections <- function(cicero_model_list, silent = FALSE) {\n",
    "  types <- vapply(cicero_model_list, FUN=class, FUN.VALUE=\"character\")\n",
    "  char_hbn <- cicero_model_list[types==\"character\"]\n",
    "  gl_only <- cicero_model_list[types==\"list\"]\n",
    "  if(!silent) {\n",
    "    print(paste(\"Successful cicero models: \", length(gl_only)))\n",
    "    print(\"Other models: \")\n",
    "    print(table(unlist(char_hbn)))\n",
    "    print(paste(\"Models with errors: \", sum(is.null(cicero_model_list))))\n",
    "  }\n",
    "\n",
    "  cors <- lapply(gl_only, function(gl)  {\n",
    "    cors <- stats::cov2cor(gl$w)\n",
    "    data.table::melt(as.data.table(cors, keep.rownames=TRUE), \n",
    "                     measure=patterns(\"[0-9]\"))\n",
    "  })\n",
    "\n",
    "  cors <- data.table::rbindlist(cors)\n",
    "  names(cors) <- c(\"Var1\", \"Var2\", \"value\")\n",
    "  data.table::setkey(cors, \"Var1\", \"Var2\")\n",
    "\n",
    "  cors_rec <- as.data.frame(cors[,list(mean_coaccess = reconcile(value)),\n",
    "                                 by=\"Var1,Var2\"])\n",
    "\n",
    "  names(cors_rec) <- c(\"Peak1\", \"Peak2\", \"coaccess\")\n",
    "  cors_rec <- cors_rec[cors_rec$Peak1 != cors_rec$Peak2,]\n",
    "  return(cors_rec)\n",
    "}\n",
    "\n",
    "reconcile <- function(values) {\n",
    "  if (length(values) == 1) return(values)\n",
    "  if (sum(values >= 0) == length(values)) return(mean(values))\n",
    "  if (sum(values <= 0) == length(values)) return(mean(values))\n",
    "  if (sum(values == 0) == length(values)) return(0)\n",
    "  return(NA_real_)\n",
    "}\n",
    "\n",
    "generate_windows <- function(window, genomic_coords) {\n",
    "  if(!is(genomic_coords, \"data.frame\")) {\n",
    "    chr_maxes <- read.table(genomic_coords)\n",
    "  } else {\n",
    "    chr_maxes <- genomic_coords\n",
    "  }\n",
    "  names(chr_maxes) <- c(\"V1\", \"V2\")\n",
    "  win_ranges <- plyr::ddply(chr_maxes, plyr::.(V1), function(x) {\n",
    "    r <- seq(from = 1, to = x$V2[1], by = window/2)\n",
    "    l <- r + window - 1\n",
    "    data.frame(start = r, end = l)\n",
    "  })\n",
    "  gr <- GenomicRanges::GRanges(win_ranges$V1,\n",
    "                               ranges=IRanges::IRanges(win_ranges$start,\n",
    "                                                       win_ranges$end))\n",
    "  return(gr)\n",
    "}\n",
    "\n",
    "get_genomic_range <- function(grs, cds, win) {\n",
    "  end1 <- as.numeric(as.character(GenomicRanges::end(grs[win])))\n",
    "  end2 <- as.numeric(as.character(GenomicRanges::start(grs[win])))\n",
    "  win_range <- cds[(fData(cds)$bp1 < end1 &\n",
    "                                fData(cds)$bp1 > end2) |\n",
    "                               (fData(cds)$bp2 < end1 &\n",
    "                                  fData(cds)$bp2 > end2), ]\n",
    "  win_range <-\n",
    "    win_range[as.character(fData(win_range)$chr) ==\n",
    "                gsub(\"chr\", \"\",\n",
    "                     as.character(GenomicRanges::seqnames(grs[win]))),]\n",
    "  fData(win_range)$mean_bp <-\n",
    "    (as.numeric(as.character(fData(win_range)$bp1)) +\n",
    "       as.numeric(as.character(fData(win_range)$bp2)))/2\n",
    "\n",
    "  return(win_range)\n",
    "}\n",
    "\n",
    "find_distance_parameter <- function(dist_mat,\n",
    "                       gene_range,\n",
    "                       maxit,\n",
    "                       null_rho,\n",
    "                       s,\n",
    "                       distance_constraint,\n",
    "                       distance_parameter_convergence) {\n",
    "  if (sum(dist_mat > distance_constraint)/2 < 1) {\n",
    "    return(\"No long edges\")\n",
    "  }\n",
    "\n",
    "  found <- FALSE\n",
    "  starting_max <- 2\n",
    "  distance_parameter <- 2\n",
    "  distance_parameter_max <- 2\n",
    "  distance_parameter_min <- 0\n",
    "  it <- 0\n",
    "  while(found != TRUE & it < maxit) {\n",
    "    vals <- exprs(gene_range)\n",
    "    cov_mat <- cov(t(vals))\n",
    "    diag(cov_mat) <- diag(cov_mat) + 1e-4\n",
    "\n",
    "    rho <- get_rho_mat(dist_mat, distance_parameter, s)\n",
    "\n",
    "    GL <- glasso::glasso(cov_mat, rho)\n",
    "    big_entries <- sum(dist_mat > distance_constraint)\n",
    "\n",
    "    if (((sum(GL$wi[dist_mat > distance_constraint] != 0)/big_entries) > 0.05) |\n",
    "        (sum(GL$wi == 0)/(nrow(GL$wi)^2) < 0.2 ) ) {\n",
    "      longs_zero <- FALSE\n",
    "    } else {\n",
    "      longs_zero <- TRUE\n",
    "    }\n",
    "\n",
    "    if (longs_zero != TRUE | (distance_parameter == 0)) {\n",
    "      distance_parameter_min <- distance_parameter\n",
    "    } else {\n",
    "      distance_parameter_max <- distance_parameter\n",
    "    }\n",
    "    new_distance_parameter <- (distance_parameter_min +\n",
    "                                 distance_parameter_max)/2\n",
    "\n",
    "    if(new_distance_parameter == starting_max) {\n",
    "      new_distance_parameter <- 2 * starting_max\n",
    "      starting_max <- new_distance_parameter\n",
    "    }\n",
    "\n",
    "    if (distance_parameter_convergence > abs(distance_parameter -\n",
    "                                             new_distance_parameter)) {\n",
    "      found <- TRUE\n",
    "    } else {\n",
    "      distance_parameter <- new_distance_parameter\n",
    "    }\n",
    "    it <- it + 1\n",
    "  }\n",
    "  if (maxit == it) warning(\"maximum iterations hit\")\n",
    "  return(distance_parameter)\n",
    "}\n",
    "\n",
    "get_rho_mat <- function(dist_matrix, distance_parameter, s) {\n",
    "  xmin <- 1000\n",
    "  out <- (1-(xmin/dist_matrix)^s) * distance_parameter\n",
    "  out[!is.finite(out)] <- 0\n",
    "  out[out < 0] <- 0\n",
    "  return(out)\n",
    "}\n",
    "\n",
    "calc_dist_matrix <- function(gene_range) {\n",
    "  dist_mat <- as.matrix(dist(fData(gene_range)$mean_bp))\n",
    "  row.names(dist_mat) <- colnames(dist_mat) <- row.names(fData(gene_range))\n",
    "\n",
    "  return(dist_mat)\n",
    "}\n",
    "\n",
    "make_ccan_graph <- function(connections_df, coaccess_cutoff) {\n",
    "  connections_df <- as.data.frame(connections_df)\n",
    "  #make graph\n",
    "  cons_info_gr <- connections_df[!is.na(connections_df$coaccess) &\n",
    "                                   connections_df$coaccess > coaccess_cutoff,]\n",
    "  if(nrow(cons_info_gr) == 0) stop(\"No connections for graph\")\n",
    "  cons_graph <- make_sparse_matrix(cons_info_gr, x.name = \"coaccess\")\n",
    "  site_graph <- igraph::graph.adjacency(cons_graph,\n",
    "                                        mode = \"undirected\",\n",
    "                                        weighted = TRUE)\n",
    "  return(site_graph)\n",
    "}\n",
    "\n",
    "#' Generate cis-co-accessibility networks (CCANs)\n",
    "#'\n",
    "#' Post process cicero co-accessibility scores to extract modules of sites that\n",
    "#' are co-accessible.\n",
    "#'\n",
    "#' @param connections_df Data frame of connections with columns: Peak1, Peak2,\n",
    "#'   coaccess. Generally, the output of \\code{\\link{run_cicero}} or\n",
    "#'   \\code{\\link{assemble_connections}}\n",
    "#' @param coaccess_cutoff_override Numeric, co-accessibility score threshold to\n",
    "#'   impose. Overrides automatic calculation.\n",
    "#' @param tolerance_digits The number of digits to calculate cutoff to. Default\n",
    "#'   is 2 (0.01 tolerance)\n",
    "#'\n",
    "#' @details CCANs are calculated by first specifying a minimum co-accessibility\n",
    "#'   score and then using the Louvain community detection algorithm on the\n",
    "#'   subgraph induced by excluding edges below this score. For this function,\n",
    "#'   either the user can specify the minimum co-accessibility using\n",
    "#'   \\code{coaccess_cutoff_override}, or the cutoff can be calculated\n",
    "#'   automatically by optimizing for CCAN number. The cutoff calculation can be\n",
    "#'   slow, so users may wish to use the \\code{coaccess_cutoff_override} after\n",
    "#'   initially calculating the cutoff to speed future runs.\n",
    "#'\n",
    "#' @return Data frame with two columns - Peak and CCAN. CCAN column indicates\n",
    "#'   CCAN assignment. Peaks not included in a CCAN are not returned.\n",
    "#' @export\n",
    "#'\n",
    "#' @examples\n",
    "#' \\dontrun{\n",
    "#'   data(\"cicero_data\")\n",
    "#'   set.seed(18)\n",
    "#'   data(\"human.hg19.genome\")\n",
    "#'   sample_genome <- subset(human.hg19.genome, V1 == \"chr18\")\n",
    "#'   sample_genome$V2[1] <- 100000\n",
    "#'   input_cds <- make_atac_cds(cicero_data, binarize = TRUE)\n",
    "#'   input_cds <- reduceDimension(input_cds, max_components = 2, num_dim=6,\n",
    "#'                                reduction_method = 'tSNE',\n",
    "#'                                norm_method = \"none\")\n",
    "#'   tsne_coords <- t(reducedDimA(input_cds))\n",
    "#'   row.names(tsne_coords) <- row.names(pData(input_cds))\n",
    "#'   cicero_cds <- make_cicero_cds(input_cds, reduced_coordinates = tsne_coords)\n",
    "#'   cicero_cons <- run_cicero(cicero_cds, sample_genome, sample_num = 2)\n",
    "#'   ccan_assigns <- generate_ccans(cicero_cons)\n",
    "#'  }\n",
    "#'\n",
    "generate_ccans <- function(connections_df,\n",
    "                           coaccess_cutoff_override = NULL,\n",
    "                           tolerance_digits = 2) {\n",
    "  assertthat::assert_that(is.data.frame(connections_df))\n",
    "  assertthat::assert_that(assertthat::has_name(connections_df, \"Peak1\"),\n",
    "                          assertthat::has_name(connections_df, \"Peak2\"),\n",
    "                          assertthat::has_name(connections_df, \"coaccess\"))\n",
    "  assertthat::assert_that(assertthat::is.number(tolerance_digits))\n",
    "  assertthat::assert_that(assertthat::is.number(coaccess_cutoff_override) |\n",
    "                            is.null(coaccess_cutoff_override),\n",
    "                          msg = paste(\"coaccess_cutoff_override must be a\",\n",
    "                                      \"number or NULL\", collapse = \" \"))\n",
    "  if (!is.null(coaccess_cutoff_override)) {\n",
    "    assertthat::assert_that(coaccess_cutoff_override <= 1 &\n",
    "                              coaccess_cutoff_override >= 0,\n",
    "                            msg = paste(\"coaccess_cutoff_override must be\",\n",
    "                                        \"between 0 and 1 (or NULL)\",\n",
    "                                        collapse = \" \"))\n",
    "  }\n",
    "\n",
    "  if (!is.null(coaccess_cutoff_override)) {\n",
    "    coaccess_cutoff <- coaccess_cutoff_override\n",
    "  } else {\n",
    "    coaccess_cutoff <- find_ccan_cutoff(connections_df, tolerance_digits)\n",
    "  }\n",
    "  print(paste(\"Coaccessibility cutoff used:\", coaccess_cutoff))\n",
    "  ccan_graph <- make_ccan_graph(connections_df,\n",
    "                                coaccess_cutoff = coaccess_cutoff)\n",
    "  comp_membership <- igraph::cluster_louvain(ccan_graph)\n",
    "  sizes <- igraph::sizes(comp_membership) > 2\n",
    "  comps_list <- unlist(as.list(igraph::membership(comp_membership)))\n",
    "  df <- data.frame(Peak = names(comps_list), CCAN = comps_list)\n",
    "  df$CCAN[!df$CCAN %in% names(sizes[sizes])] <- NA\n",
    "  df <- df[!is.na(df$CCAN),]\n",
    "  return(df)\n",
    "}\n",
    "\n",
    "find_ccan_cutoff <- function(connection_df, tolerance_digits) {\n",
    "  connection_df <- connection_df[connection_df$coaccess > 0,]\n",
    "  tolerance <- 10^-(tolerance_digits)\n",
    "  bottom <- 0\n",
    "  top <- 1\n",
    "  while ((top - bottom) > tolerance) {\n",
    "    test_val <- bottom + round((top - bottom)/2, digits = tolerance_digits + 1)\n",
    "    ccan_num_test <- number_of_ccans(connection_df, test_val)\n",
    "    next_step <- test_val\n",
    "    repeat{\n",
    "      next_step <- next_step + (top - bottom)/10\n",
    "      ccan_num_test2 <- number_of_ccans(connection_df, next_step)\n",
    "      if(ccan_num_test2 != ccan_num_test){\n",
    "        break\n",
    "      }\n",
    "    }\n",
    "    if (ccan_num_test > ccan_num_test2) {\n",
    "      top <- test_val\n",
    "    } else {\n",
    "      bottom <- test_val\n",
    "    }\n",
    "  }\n",
    "  return(round((top + bottom)/2, digits = tolerance_digits))\n",
    "}\n",
    "\n",
    "number_of_ccans <- function(connections_df, coaccess_cutoff) {\n",
    "  ccan_graph <- make_ccan_graph(connections_df,\n",
    "                                coaccess_cutoff = coaccess_cutoff)\n",
    "  comp_membership <- igraph::cluster_louvain(ccan_graph)\n",
    "  return(sum(igraph::sizes(comp_membership) > 2))\n",
    "}\n",
    "\n",
    "#' Find CCANs that overlap each other in genomic coordinates\n",
    "#'\n",
    "#' @param ccan_assignments A data frame where the first column is the peak and\n",
    "#'   the second is the CCAN assignment. For example, output of\n",
    "#'   \\code{generate_ccans}.\n",
    "#' @param min_overlap The minimum base pair overlap to count as overlapping.\n",
    "#'\n",
    "#' @return A data frame with two columns, CCAN1 and CCAN2. CCANs in this list\n",
    "#'   are overlapping. The data frame is reciprocal (if CCAN 2 overlaps CCAN 1,\n",
    "#'   there will be two rows, 1,2 and 2,1).\n",
    "#'\n",
    "#' @examples\n",
    "#'   ccan_df <- data.frame(peak = c(\"chr18_1408345_1408845\", \"chr18_1779830_1780330\", \n",
    "#'                                  \"chr18_1929095_1929595\", \"chr18_1954501_1954727\",\n",
    "#'                                  \"chr18_2049865_2050884\", \"chr18_2083726_2084102\",\n",
    "#'                                  \"chr18_2087935_2088622\", \"chr18_2104705_2105551\",\n",
    "#'                                  \"chr18_2108641_2108907\"), \n",
    "#'                         CCAN = c(1,2,2,2,3,3,3,3,2))\n",
    "#'   olap_ccans <- find_overlapping_ccans(ccan_df)\n",
    "#' \n",
    "#'\n",
    "#' @export\n",
    "find_overlapping_ccans <- function(ccan_assignments, min_overlap=1) {\n",
    "  ccan_assignments <- ccan_assignments[,c(1,2)]\n",
    "  names(ccan_assignments) <- c(\"Peak\", \"CCAN\")\n",
    "  ccans <- df_for_coords(ccan_assignments$Peak)\n",
    "  ccans$CCAN <- ccan_assignments$CCAN\n",
    "  ccan_info <- plyr::ddply(ccans, plyr::.(CCAN), function(ccan) {\n",
    "    return(data.frame(ccan_coords = paste(ccan$chr[1], bp1 = min(ccan$bp1),\n",
    "                                          bp2 = max(ccan$bp2), sep=\"_\")))\n",
    "  })\n",
    "\n",
    "  ccan_ranges <- ranges_for_coords(ccan_info$ccan_coords,\n",
    "                                   meta_data_df = ccan_info)\n",
    "  ol <- GenomicRanges::findOverlaps(ccan_ranges, ccan_ranges,\n",
    "                                    minoverlap=min_overlap, #maxgap = 0,\n",
    "                                    select=\"all\")\n",
    "  olaps <- data.frame(\n",
    "    CCAN1 = GenomicRanges::mcols(ccan_ranges[\n",
    "      S4Vectors::queryHits(ol)])@listData$CCAN,\n",
    "    CCAN2 = GenomicRanges::mcols(ccan_ranges[\n",
    "      S4Vectors::subjectHits(ol)])@listData$CCAN)\n",
    "  olaps <- olaps[!duplicated(olaps),]\n",
    "  olaps <- olaps[olaps$CCAN1 != olaps$CCAN2, ]\n",
    "  return(olaps)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb32386e-d4e5-478a-968a-7fb53d01f419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90, 74, 88, ..., 75, 93, 99],\n",
       "       [13, 58, 71, ...,  8, 81, 65],\n",
       "       [77,  8, 41, ..., 64, 41, 83],\n",
       "       ...,\n",
       "       [53, 36, 27, ..., 58, 29, 97],\n",
       "       [86, 45, 33, ..., 18, 50, 33],\n",
       "       [20,  4, 10, ..., 82,  7, 69]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atac.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "20fdf4de-6420-40a6-b77e-886ef60422bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [1,3,7,5,6],\n",
    "    [2,3,4,5,2],\n",
    "    [3,3,9,5,10],\n",
    "    [4,3,4,8,6],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9a1aaa5f-761e-4911-a6a5-0eb21ce2aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to obtain from distance constraints\n",
    "potential =  np.array([\n",
    "    [0,1,1,0],\n",
    "    [0,0,0,0],\n",
    "    [1,0,0,1],\n",
    "    [1,0,1,0],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "60176c4f-24e8-41b2-9982-38f0e73d9550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 µs ± 1.33 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "idx = np.where(np.triu(potential,1)!=0)\n",
    "corr = np.zeros(potential.shape)\n",
    "for i in range(len(idx[0])):\n",
    "    corr[idx[0][i], idx[1][i]] = np.corrcoef([data[idx[0][i]],data[idx[1][i]]])[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8401ba99-e6ee-432d-b628-1718ef7bf14c",
   "metadata": {},
   "source": [
    "### Comparison speed pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cc8b97b0-5f82-45e7-8c7a-3eb88e7bc9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_correlation(A, B):\n",
    "    am = A - np.mean(A, axis=0, keepdims=True)\n",
    "    bm = B - np.mean(B, axis=0, keepdims=True)\n",
    "    return am.T @ bm /  (np.sqrt(\n",
    "        np.sum(am**2, axis=0,\n",
    "               keepdims=True)).T * np.sqrt(\n",
    "        np.sum(bm**2, axis=0, keepdims=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6800c49f-153d-4a9b-a2a5-65d3166f7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(10, size = (3,50000))\n",
    "B = np.random.randint(10, size = (3,50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "25d48e62-741b-4527-af50-b808eeb9da0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.42 ms ± 14.8 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pearsonr(A[1,:],B[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d0875fc9-3cdd-4f57-9cd1-01c04ac7841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356 µs ± 4.11 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "numpy.corrcoef(A[1,:],B[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "18edd734-8a17-4a30-ba9e-8bf0e84275d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 µs ± 4.05 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pairwise_correlation(A[1,:],B[1,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
